<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?" />
  <meta name="keywords" content="SWE-Perf, Code Performance, Optimization, Large Language Models, LLM, Repository-level, Benchmark" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || []

      function gtag() {
        dataLayer.push(arguments)
      }

      gtag("js", new Date())

      gtag("config", "G-PYVRSFMDRL")
    </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css" />
  <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./css/index.css" />
  <link rel="icon" href="./images/favicon.svg" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>

  <style>
    /* Navigation Header */
    .main-nav {
      background: #ffffff !important;
      border-bottom: 1px solid #e2e8f0 !important;
      padding: 1rem 0 !important;
      position: sticky !important;
      top: 0 !important;
      z-index: 1000 !important;
      box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1) !important;
    }

    .nav-container {
      max-width: 1200px !important;
      margin: 0 auto !important;
      padding: 0 2rem !important;
      display: flex !important;
      justify-content: space-between !important;
      align-items: center !important;
    }

    .nav-brand {
      font-family: Inter, sans-serif !important;
      font-size: 1.75rem !important;
      font-weight: 700 !important;
      color: #0f172a !important;
      text-decoration: none !important;
    }

    .nav-links {
      display: flex !important;
      gap: 2rem !important;
      align-items: center !important;
    }

    .nav-link {
      font-family: Inter, sans-serif !important;
      font-size: 1.125rem !important;
      font-weight: 500 !important;
      color: #64748b !important;
      text-decoration: none !important;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      transition: all 0.2s ease;
    }

    .nav-link:hover {
      color: #FF2B54 !important;
      background: #fff1f3;
    }

    .nav-link.active {
      color: #FF2B54 !important;
      background: #ffe4e8;
      font-weight: 600 !important;
    }

    .nav-new-badge {
      display: inline-flex;
      align-items: center;
      background: linear-gradient(135deg, #FF2B54, #e21947);
      color: white !important;
      padding: 0.25rem 0.625rem;
      border-radius: 9999px;
      font-size: 0.75rem !important;
      font-weight: 700 !important;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-left: 0.5rem;
      box-shadow: 0 1px 2px 0 rgb(0 0 0 / 0.05);
      animation: pulse 2s infinite;
    }

    @keyframes pulse {

      0%,
      100% {
        transform: scale(1);
      }

      50% {
        transform: scale(1.05);
      }
    }

    /* Enhanced body and content font sizes */
    body {
      font-family: Inter, sans-serif !important;
      font-size: 18px !important;
    }

    .title.is-1.publication-title {
      font-family: Inter, sans-serif !important;
      font-size: 3rem !important;
      font-weight: 700 !important;
      line-height: 1.2 !important;
      letter-spacing: -0.025em !important;
    }

    .title.is-3 {
      font-family: Inter, sans-serif !important;
      font-size: 2rem !important;
      font-weight: 600 !important;
    }

    .is-size-5.publication-authors {
      font-family: Inter, sans-serif !important;
      font-size: 1.125rem !important;
      font-weight: 500 !important;
    }

    .subtitle {
      font-family: Inter, sans-serif !important;
      font-size: 1.25rem !important;
      font-weight: 500 !important;
      line-height: 1.6 !important;
    }

    .content p {
      font-family: Inter, sans-serif !important;
      font-size: 1.125rem !important;
      line-height: 1.7 !important;
    }

    .button {
      font-family: Inter, sans-serif !important;
      font-size: 1rem !important;
      font-weight: 500 !important;
    }

    /* Mobile responsive */
    @media (max-width: 768px) {
      body {
        font-size: 16px !important;
      }

      .nav-container {
        padding: 0 1rem;
      }

      .nav-links {
        gap: 1rem;
      }

      .nav-link {
        font-size: 1rem !important;
        padding: 0.5rem 0.75rem;
      }

      .nav-brand {
        font-size: 1.5rem !important;
      }

      .title.is-1.publication-title {
        font-size: 2.25rem !important;
      }

      .title.is-3 {
        font-size: 1.75rem !important;
      }

      .is-size-5.publication-authors {
        font-size: 1rem !important;
      }

      .subtitle {
        font-size: 1.125rem !important;
      }

      .content p {
        font-size: 1rem !important;
      }

      .button {
        font-size: 0.875rem !important;
      }
    }
  </style>
</head>

<body>
    <!-- Navigation Header -->
    <nav class="main-nav">
        <div class="nav-container">
            <a href="index.html" class="nav-brand">SWE-Perf</a>
            <div class="nav-links">
                <!-- FIX 2: Moved 'active' class to the correct link for this page. -->
                <a href="index.html" class="nav-link active">Overview</a>
                <a href="leaderboard.html" class="nav-link">Leaderboard</a>
            </div>
        </div>
    </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Xinyi He</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#">Qian Liu</a><sup>2‚Å∫</sup>,</span>
              <span class="author-block">
                <a href="#">Mingzhe Du</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="#">Lin Yan</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#">Zhijie Fan</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#">Yiming Huang</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="#">Zejian Yuan</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#">Zejun Ma</a><sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Xi'an Jiaotong University</span>
              <span class="author-block"><sup>2</sup>TikTok</span>
              <span class="author-block"><sup>3</sup>National University of Singapore</span>
              <span class="author-block"><sup>4</sup>University of California San Diego</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/swe-perf/swe-perf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="#"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;">
                    </span>
                    <span>Data</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <!-- center the image -->
          <img src="./images/wordcloud_human_patch.png" alt="SWE-Perf: Human Expert Optimization Strategies" class="teaser-image center" width="80%" />
        </div>

        <h2 class="subtitle has-text-centered">
          <span class="dnerf">SWE-Perf</span> is the first benchmark designed to systematically evaluate LLMs on code performance optimization tasks within genuine repository contexts. We introduce <strong>140 real-world optimization instances</strong> derived from performance-improving pull requests on popular GitHub repositories.
        </h2>

      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Optimizing code performance is paramount in real-world software engineering and critical for production-level systems. While Large Language Models (LLMs) have demonstrated impressive capabilities in code generation and bug fixing, their proficiency in enhancing code performance at the repository level remains largely unexplored. To address this, we introduce <strong>SWE-Perf</strong>, the first benchmark meticulously designed to systematically evaluate LLMs on code performance optimization tasks within genuine repository contexts.
            </p>
            <p>
              SWE-Perf comprises 140 instances, each derived from a performance-improving pull request curated from popular GitHub repositories. Each benchmark instance provides the relevant codebase, specific performance-related tests, the expert-authored patch, and the corresponding runtime metrics. Through systematic evaluation of representative models spanning agentless and agent-based approaches, we identify a substantial capability gap between existing LLMs and expert-level optimization performance, highlighting critical research opportunities in this emerging field.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">The SWE-Perf Benchmark</h2>
          <div class="content has-text-justified">
            <p>
              The core task in SWE-Perf is to optimize the performance of a given repository codebase. The model receives the source code and a set of performance-related unit tests. It must then generate a patch that, when applied, reduces the execution time of these tests without breaking their correctness. The model's generated patch is evaluated against the original runtime and the runtime achieved by a human expert's patch, providing a clear measure of performance improvement.
            </p>
            <div style="text-align: center; margin: 40px 0;">
                <img src="./images/sweperf_taskflow.png" alt="Best AI Model Optimization Strategy" style="max-width: 600px; width: 100%; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
            </div>
            <p style="text-align: center; width: 100%;">
                Figure 1: The workflow of our SWE-Perf benchmark which evaluates code performance optimization capabilities of
                language models. Model performance is evaluated by the runtime gains on the tests, with
                expert performance as reference.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Data Collection Pipeline</h2>
          <div class="content has-text-justified">
            <p>
              Creating a high-quality performance optimization benchmark is challenging. We developed a rigorous five-phase pipeline to mine and validate instances from thousands of pull requests on popular open-source projects.
            </p>
            <div style="text-align: center; margin: 40px 0;">
                <img src="./images/sweperf_collection.jpg" alt="AI Model Optimization Patterns" style="max-width: 600px; width: 100%; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
            </div>
             <p style="text-align: center; width: 100%;">
                Figure 2: DeepSeek-V3 model optimization patterns showing typical AI approach to code improvement.
            </p>
            
            <p>
                This process resulted in 140 high-quality instances from 9 diverse and widely-used repositories, including `xarray`, `scikit-learn`, and `sympy`.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Evaluation and Key Findings</h2>
          <div class="content has-text-justified">
            <p>
                We evaluated several state-of-the-art models and agentic frameworks, including Claude 3, DeepSeek, and approaches like Agentless and OpenHands. Our evaluation rests on three metrics: <strong>Apply</strong> (can the patch be applied cleanly?), <strong>Correctness</strong> (do all tests still pass?), and <strong>Performance</strong> (how much faster is the code?).
            </p>
            
            <div style="background: linear-gradient(135deg, #FF2B54 0%, #e21947 100%); color: white; padding: 2rem; border-radius: 12px; margin: 3rem 0; text-align: center;">
              <h3 style="font-size: 1.5rem; font-weight: 700; margin-bottom: 1rem; color: white;">üîç Key Insight: Significant AI-Human Gap</h3>
              <p style="font-size: 1.125rem; opacity: 0.95;">Best AI model achieves <strong style="color: white;">13.02%</strong> performance improvement vs Human experts at <strong style="color: white;">71.20%</strong> - a gap of <strong style="color: white;">58.18%</strong></p>
            </div>

            <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 2rem; align-items: center; margin: 3rem 0;">
                <div style="text-align: center; padding: 2rem; background: white; border-radius: 12px; box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1); border: 1px solid #e2e8f0;">
                  <h3 style="font-size: 1.25rem; font-weight: 600; margin-bottom: 1rem; color: #0f172a;">Best AI Model (Agentless)</h3>
                  <img src="./images/wordcloud_agentless_patch.png" alt="AI Model Word Cloud" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; margin-bottom: 1rem;">
                  <p><strong>Performance:</strong> 13.02%</p>
                  <p>Focuses on low-level operations like <em>append</em>, <em>get</em>, <em>set</em></p>
                </div>
                <div style="font-size: 1.5rem; font-weight: 700; color: #FF2B54; text-align: center; padding: 1rem;">VS</div>
                <div style="text-align: center; padding: 2rem; background: white; border-radius: 12px; box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1); border: 1px solid #e2e8f0;">
                  <h3 style="font-size: 1.25rem; font-weight: 600; margin-bottom: 1rem; color: #0f172a;">Human Expert</h3>
                  <img src="./images/wordcloud_human_patch.png" alt="Human Expert Word Cloud" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; margin-bottom: 1rem;">
                  <p><strong>Performance:</strong> 71.20%</p>
                  <p>Uses high-level abstractions like <em>parser</em>, <em>state</em>, <em>component</em></p>
                </div>
            </div>
            <div style="text-align: center; padding: 1.5rem; background: #fff0f2; border: 1px solid #ffb3c1; border-radius: 8px; margin-top: 2rem; color: #FF2B54; font-size: 1.125rem; font-weight: 600;">
                <strong>58.18% Performance Gap</strong> - AI models need to learn architectural thinking
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Key Findings</h2>
          <div class="content has-text-justified">
            <h3 class="title is-4">Finding 1: A Major Gap Exists Between LLMs and Human Experts</h3>
            <p>
                Our primary finding is that all current models, regardless of the approach, fall significantly short of human expert performance. The best-performing method, Agentless, achieved a performance improvement of 13.02%, while human experts achieved 71.20%‚Äîa gap of over 58%. This holds true across nearly all repositories in our dataset.
            </p>
            
            <h3 class="title is-4">Finding 2: Models Struggle with High-Level, Architectural Changes</h3>
            <p>
                Why do models underperform? We analyzed the code changes made by models versus those made by experts. Our findings indicate a stark difference in strategy.
            </p>
            <ul style="margin-left: 2rem; margin-bottom: 2rem;">
                <li><strong>Models</strong> tend to make low-level, localized changes. Their patches are filled with terms like `append`, `get`, `set`, and simple control flow logic (`if`, `not`, `and`). They perform micro-optimizations.</li>
                <li><strong>Experts</strong> focus on higher-level, architectural improvements. Their patches frequently involve restructuring key components and refining abstractions, using terms like `parser`, `state`, `component`, and `listener`. They perform macro-optimizations.</li>
            </ul>
            
            <h3 class="title is-4">Finding 3: Increasing Edits Correlates with Better Performance</h3>
            <p>
                Interestingly, we found that for the best-performing models, making more edits often leads to better performance. While experts can achieve significant gains with few changes, the `Agentless` model shows a distinct upward trend in performance as the number of edited functions increases. This suggests that current models may need to perform more extensive, quantitative changes to achieve a qualitative leap in optimization.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Conclusion</h2>
          <div class="content has-text-justified">
            <p>
              In conclusion, SWE-Perf addresses a critical gap in current benchmarking by providing a repository-level dataset focused on realistic code performance optimization. Our benchmark and comprehensive baseline assessments reveal substantial room for improvement in current models, underscoring the complexity of cross-module and repository-scale optimizations. By establishing this new standard and evaluation framework, we pave the way for future research to advance the capabilities of language models in delivering meaningful, performance-aware code enhancements at scale.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <!-- FIX 3: Updated BibTeX key to be consistent with the paper's authors and title. -->
      <pre><code>@article{he2025sweperf,
    title={SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?},
    author={He, Xinyi and Liu, Qian and Du, Mingzhe and Yan, Lin and Fan, Zhijie and Huang, Yiming and Yuan, Zejian and Ma, Zejun},
    journal={arXiv preprint arXiv:XXXX.XXXXX},
    year={2025}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">

      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Please reach out to <a href="mailto:qian.liu@tiktok.com">qian.liu@tiktok.com</a> for questions or
              feedback on SWE-Perf. We are also open to collaborations and suggestions for improving the benchmark.
              This work was conducted during Xinyi and Yiming's internship at TikTok.
            </p>
            <p>
              The website template is adapted from <a href="https://livecodebench.github.io" target="_blank">LiveCodeBench</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>